{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmiHInUa7HS9hcUU1vA1v9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haneulllll/Deeplearning/blob/practice/lab3_Regularization_and_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regularization\n",
        "\n",
        "**Dropout 기법**"
      ],
      "metadata": {
        "id": "UKoDlP6TuYZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**import package**"
      ],
      "metadata": {
        "id": "0tRCFsAoubnv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "Qvn_RkfYufWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPU/CPU setting**\n",
        "\n",
        "\n",
        "1. 상단메뉴의 런타임 - 런타임 유형 변경 - 하드웨어 가속기 메뉴에서 GPU를 선택 - 저장"
      ],
      "metadata": {
        "id": "U9KtItsTxAoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda' :\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa-KZdCixGeZ",
        "outputId": "b68a61e4-9d6c-4d90-e80e-05b07cb65b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터 불러오기**"
      ],
      "metadata": {
        "id": "npRRDC8hxVs2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgIRf2JqxWCU",
        "outputId": "0f47dbf0-6a01-4052-b957-ff1a005f15d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 35595368.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 959384.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 10157850.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7756729.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**데이터를 배치화하기**"
      ],
      "metadata": {
        "id": "oXok8MOtxaI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "minibatch의 크기는 32로 설정"
      ],
      "metadata": {
        "id": "4ufyrzesrAZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "zEOZJ1KExeh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 생성**\n",
        "\n",
        "-- Hidden layer 수 : 3개 (784 - 512 - 256 - 128 - 10)\n",
        "\n",
        "-- 활성화 함수 : ReLU\n",
        "\n",
        "-- 정규화 기법 : dropout , Batch normalization 이용\n",
        "\n",
        "-- Optimization 기법 : Adam"
      ],
      "metadata": {
        "id": "OnT6I3mrxiLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP_Dropout(nn.Module) :\n",
        "  def __init__(self) :\n",
        "    super(MLP_Dropout, self).__init__()\n",
        "    self.fc1 = nn.Linear(784,512)\n",
        "    self.fc2 = nn.Linear(512,256)\n",
        "    self.fc3 = nn.Linear(256,128)\n",
        "    self.fc4 = torch.nn.Linear(128,10)\n",
        "    self.dp1 = nn.Dropout(p=0.3)\n",
        "    self.dp2 = nn.Dropout(p=0.2)\n",
        "    self.dp3 = nn.Dropout(p=0.1)\n",
        "    self.bn1 = nn.BatchNorm1d(512)\n",
        "    self.bn2 = nn.BatchNorm1d(256)\n",
        "    self.bn3 = nn.BatchNorm1d(128)\n",
        "\n",
        "  def forward(self, x) :\n",
        "    h1 = F.relu(self.bn1(self.fc1(x)))\n",
        "    h1dp = self.dp1(h1)\n",
        "    h2 = F.relu(self.bn2(self.fc2(h1dp)))\n",
        "    h2dp = self.dp2(h2)\n",
        "    h3 = F.relu(self.bn3(self.fc3(h2dp)))\n",
        "    h3dp = self.dp3(h3)\n",
        "    output = self.fc4(h3dp)\n",
        "    return output"
      ],
      "metadata": {
        "id": "3LXkIb_90cR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파라미터 정의 -> 반복횟수 30으로 설정 / learning_rate는 0.001로 설정\n",
        "\n",
        "num_epochs = 30\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "Xho9e_zN1nWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 정의\n",
        "\n",
        "model = MLP_Dropout().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "3Zw5kpob1sCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train 과정**"
      ],
      "metadata": {
        "id": "zt0u0qgZ3VRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = []\n",
        "for epoch_num in range(num_epochs) :\n",
        "  average_cost = 0\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, (x_data, y_label) in enumerate(train_loader) :\n",
        "    num_of_mini_batch = len(train_loader)\n",
        "\n",
        "    x_data = x_data.reshape(-1, 28*28)\n",
        "    input_image = x_data.to(device)\n",
        "    label = y_label.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    y_predict = model(input_image)\n",
        "    loss = criterion(y_predict, label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    average_cost = average_cost + (loss.item()/num_of_mini_batch)\n",
        "    loss_list.append(loss)\n",
        "\n",
        "  print(\"Epoch {} Loss {:.5f}\".format((epoch_num+1), average_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYB9O_7T3Vjy",
        "outputId": "cfcab718-08ab-49db-8f27-f89b9d076f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss 0.27662\n",
            "Epoch 2 Loss 0.15501\n",
            "Epoch 3 Loss 0.12642\n",
            "Epoch 4 Loss 0.10693\n",
            "Epoch 5 Loss 0.09167\n",
            "Epoch 6 Loss 0.08518\n",
            "Epoch 7 Loss 0.07368\n",
            "Epoch 8 Loss 0.06882\n",
            "Epoch 9 Loss 0.06585\n",
            "Epoch 10 Loss 0.05944\n",
            "Epoch 11 Loss 0.05515\n",
            "Epoch 12 Loss 0.05375\n",
            "Epoch 13 Loss 0.04891\n",
            "Epoch 14 Loss 0.04985\n",
            "Epoch 15 Loss 0.04078\n",
            "Epoch 16 Loss 0.04378\n",
            "Epoch 17 Loss 0.03995\n",
            "Epoch 18 Loss 0.04135\n",
            "Epoch 19 Loss 0.03569\n",
            "Epoch 20 Loss 0.03713\n",
            "Epoch 21 Loss 0.03619\n",
            "Epoch 22 Loss 0.03414\n",
            "Epoch 23 Loss 0.03359\n",
            "Epoch 24 Loss 0.03188\n",
            "Epoch 25 Loss 0.03157\n",
            "Epoch 26 Loss 0.02898\n",
            "Epoch 27 Loss 0.02871\n",
            "Epoch 28 Loss 0.02717\n",
            "Epoch 29 Loss 0.02778\n",
            "Epoch 30 Loss 0.02695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation 과정**\n",
        "\n",
        "-- dropout을 적용하지 않으므로 model을 평가모드로 전환"
      ],
      "metadata": {
        "id": "hZgWga6x3hY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad() :\n",
        "  num_total_data = 0\n",
        "  correct = 0\n",
        "  model.eval()\n",
        "  for batch_idx, (images, labels) in enumerate(test_loader) :\n",
        "\n",
        "    images = images.reshape(-1, 28*28)\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    outputs_softmax = F.softmax(outputs, dim=1)\n",
        "    predicted = torch.argmax(outputs_softmax, dim=1)\n",
        "\n",
        "    num_total_data += len(images)\n",
        "    answer = sum(labels == predicted).item()\n",
        "    correct += answer\n",
        "\n",
        "print(\"Model accuracy {:.5f}%\".format((correct/num_total_data)*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEEKIJJ43mYD",
        "outputId": "8597fd39-e35f-4a59-f8b9-856fbed152ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy 98.60000%\n"
          ]
        }
      ]
    }
  ]
}